{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal Detector",
      "provenance": [],
      "authorship_tag": "ABX9TyNF8xY+yTDOaQpHwCUsEaM9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RosieP/animal-detector/blob/master/Animal_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path, PurePath\n",
        "from pprint import pprint\n",
        "from statistics import mean\n",
        "\n",
        "import cv2 as cv\n",
        "import humanfriendly\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "DEFAULT_CONFIDENCE_THRESHOLD = 0.5\n",
        "DETECTION_FILENAME_INSERT = \"_detections\"\n",
        "DISPLAY_RESULTS = False\n",
        "\n",
        "# Don't enable. Makes things worse.\n",
        "ENABLE_ENCHANCER = False\n",
        "\n",
        "\n",
        "def get_output_file(input_file):\n",
        "    return Path(\n",
        "        \"out/\",\n",
        "        PurePath(input_file).stem + datetime.now().strftime(\"_%H_%M_%d_%m_%Y\") + \".mp4\",\n",
        "    )\n",
        "\n",
        "\n",
        "def image_resize(image, width=None, height=None, inter=cv.INTER_LANCZOS4):\n",
        "    # initialize the dimensions of the image to be resized and\n",
        "    # grab the image size\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if both the width and height are None, then return the\n",
        "    # original image\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "\n",
        "    # check to see if the width is None\n",
        "    if width is None:\n",
        "        # calculate the ratio of the height and construct the\n",
        "        # dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "\n",
        "    # otherwise, the height is None\n",
        "    else:\n",
        "        # calculate the ratio of the width and construct the\n",
        "        # dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "\n",
        "    return cv.resize(image, dim, interpolation=inter)\n",
        "\n",
        "\n",
        "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\n",
        "wb = cv.xphoto.createSimpleWB()\n",
        "wb.setP(0.3)\n",
        "\n",
        "FILE_INPUT = \"cat_3.mp4\"\n",
        "FILE_OUTPUT = get_output_file(FILE_INPUT)\n",
        "\n",
        "# Checks and deletes the output file\n",
        "# You cant have a existing file or it will through an error\n",
        "if os.path.isfile(FILE_OUTPUT):\n",
        "    os.remove(FILE_OUTPUT)\n",
        "\n",
        "# Playing video from file\n",
        "print(\"[INFO] :: Opening file {0}\".format(FILE_INPUT))\n",
        "cap = cv.VideoCapture(FILE_INPUT)\n",
        "\n",
        "n_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "fps = cap.get(cv.CAP_PROP_FPS)\n",
        "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
        "# We convert the resolutions from float to integer.\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'output.avi' file.\n",
        "print(\"[INFO] :: Writing to file {0}\".format(FILE_OUTPUT))\n",
        "fourcc = cv.VideoWriter_fourcc(*\"mp4v\")\n",
        "out_video = cv.VideoWriter(str(FILE_OUTPUT), fourcc, fps, (frame_width, frame_height),)\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "classes = {}\n",
        "bbox_categories = [\n",
        "    {\"id\": 0, \"name\": \"empty\"},\n",
        "    {\"id\": 1, \"name\": \"animal\"},\n",
        "    {\"id\": 2, \"name\": \"person\"},\n",
        "    {\"id\": 3, \"name\": \"group\"},  # group of animals\n",
        "    {\"id\": 4, \"name\": \"vehicle\"},\n",
        "]\n",
        "detections = {}\n",
        "detections[\"classes\"] = []\n",
        "detections[\"scores\"] = []\n",
        "detections[\"boxes\"] = []\n",
        "detections[\"numbers\"] = []\n",
        "detections[\"frames\"] = []\n",
        "\n",
        "for cat in bbox_categories:\n",
        "    classes[int(cat[\"id\"])] = cat[\"name\"]\n",
        "\n",
        "\n",
        "def load_model(checkpoint):\n",
        "    \"\"\"\n",
        "    Load a detection model (i.e., create a graph) from a .pb file\n",
        "    \"\"\"\n",
        "\n",
        "    detection_graph = tf.Graph()\n",
        "    with detection_graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(checkpoint, \"rb\") as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name=\"\")\n",
        "\n",
        "    return detection_graph\n",
        "\n",
        "\n",
        "def enchance_image(frame):\n",
        "    temp_img = frame\n",
        "    img_wb = wb.balanceWhite(temp_img)\n",
        "    img_lab = cv.cvtColor(img_wb, cv.COLOR_BGR2Lab)\n",
        "    l, a, b = cv.split(img_lab)\n",
        "    img_l = clahe.apply(l)\n",
        "    img_clahe = cv.merge((img_l, a, b))\n",
        "    return cv.cvtColor(img_clahe, cv.COLOR_Lab2BGR)\n",
        "\n",
        "\n",
        "def check_detections(preds):\n",
        "    return None\n",
        "\n",
        "\n",
        "def postprocess_all(detections, n_frames):\n",
        "    print(\n",
        "        \"[INFO] :: Going through {0} detections and {1} frames\".format(\n",
        "            len(detections[\"frames\"]), n_frames\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"[DEBUG] :: Length Classes: {0}, Length Scores: {1}, Length Boxes: {2}, Length Frames: {3}\".format(\n",
        "            len(detections[\"classes\"]),\n",
        "            len(detections[\"scores\"]),\n",
        "            len(detections[\"boxes\"]),\n",
        "            len(detections[\"frames\"]),\n",
        "        ),\n",
        "    )\n",
        "    n_frames = len(detections[\"frames\"])\n",
        "    for i in range(n_frames):\n",
        "        classes = detections[\"classes\"][i]\n",
        "        scores = detections[\"scores\"][i]\n",
        "        bboxes = detections[\"boxes\"][i]\n",
        "        num_detections = detections[\"numbers\"][i]\n",
        "        frame = detections[\"frames\"][i]\n",
        "\n",
        "        for j in range(num_detections):\n",
        "            class_id = int(classes[j])\n",
        "            score = float(scores[j])\n",
        "            bbox = [float(v) for v in bboxes[j]]\n",
        "            frame = postprocess(frame, class_id, score, bbox)\n",
        "        # print(\"[DEBUG] :: Writing to file frame {0}\".format(i))\n",
        "        out_video.write(frame)\n",
        "\n",
        "        if DISPLAY_RESULTS:\n",
        "            # Display the resulting frame\n",
        "            cv.imshow(\"Animals Detection. Frames number {0}\".format(n_frames), frame)\n",
        "            # Close window when \"Q\" button pressed\n",
        "            if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                print(\"[WARN] :: Exiting on button Q pressed\")\n",
        "                break\n",
        "\n",
        "\n",
        "def postprocess(frame, class_id, score, bbox):\n",
        "    # frame = image_resize(frame, width=800)\n",
        "    # frame = enchance_image(frame)\n",
        "    if score > DEFAULT_CONFIDENCE_THRESHOLD:\n",
        "        left = bbox[1] * cols\n",
        "        top = bbox[0] * rows\n",
        "        right = bbox[3] * cols\n",
        "        bottom = bbox[2] * rows\n",
        "        cv.rectangle(\n",
        "            frame,\n",
        "            (int(left), int(top)),\n",
        "            (int(right), int(bottom)),\n",
        "            (125, 255, 51),\n",
        "            thickness=2,\n",
        "        )\n",
        "        label = \"%.2f\" % score\n",
        "        if classes:\n",
        "            assert class_id < len(classes)\n",
        "            label = \"%s:%s\" % (classes[class_id], label)\n",
        "            # print(\"[DEBUG] :: Found {0}\".format(label))\n",
        "        label_size, base_line = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "        top = max(top, label_size[1])\n",
        "        cv.rectangle(\n",
        "            frame,\n",
        "            (int(left), int(top - round(1.5 * label_size[1]))),\n",
        "            (int(left + round(1.5 * label_size[0])), int(top + base_line)),\n",
        "            (255, 255, 255),\n",
        "            cv.FILLED,\n",
        "        )\n",
        "        cv.putText(\n",
        "            frame,\n",
        "            label,\n",
        "            (int(left), int(top)),\n",
        "            cv.FONT_HERSHEY_SIMPLEX,\n",
        "            0.75,\n",
        "            (0, 0, 0),\n",
        "            1,\n",
        "        )\n",
        "    return frame\n",
        "\n",
        "\n",
        "def draw_predictions(classId, conf, left, top, right, bottom):\n",
        "    pass\n",
        "\n",
        "\n",
        "# def write_raw_video(frames):\n",
        "#     # Saves for video\n",
        "#     for frame in frames:\n",
        "#         out_video.write(frame)\n",
        "\n",
        "#         # # Display the resulting frame\n",
        "#         # cv.imshow(\n",
        "#         #     \"Animals Detection. Frames number {0}\".format(n_frames), frame\n",
        "#         # )\n",
        "#         # # Close window when \"Q\" button pressed\n",
        "#         # if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "#         #     print(\"[WARN] :: Exiting on button Q pressed\")\n",
        "#         #     break\n",
        "\n",
        "\n",
        "def calculate_stats(n_frames, detections):\n",
        "    print(\"[INFO] :: Video length {} frames\".format(n_frames))\n",
        "    avg_score = []\n",
        "    # [item for sublist in l for item in sublist]\n",
        "    avg_score = [\n",
        "        score\n",
        "        for subscore in detections[\"scores\"]\n",
        "        for score in subscore\n",
        "        if score > DEFAULT_CONFIDENCE_THRESHOLD\n",
        "    ]\n",
        "    print(\"[INFO] :: Average score is {}\".format(mean(avg_score)))\n",
        "    avg_detect = len(avg_score)\n",
        "    print(\"[INFO] :: Number of meaningful detections is {}\".format(avg_detect))\n",
        "    print(\"[INFO] :: Average detections per frame is {0}\".format(avg_detect / n_frames))\n",
        "    return avg_score, avg_detect\n",
        "\n",
        "\n",
        "def find_videos(*kwargs):\n",
        "    return []\n",
        "\n",
        "\n",
        "def load_and_run_detector(\n",
        "    model_file, video_file_names, confidence_threshold, output_dir,\n",
        "):\n",
        "    model_file = \"megadetector_v3.pb\"\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # python run_tf_detector.py \"D:\\temp\\models\\object_detection\\megadetector\\megadetector_v2.pb\" --video \"D:\\temp\\demo_images\\test\\S1_J08_R1_PICT0120.JPG\"\n",
        "    # python run_tf_detector.py \"D:\\temp\\models\\object_detection\\megadetector\\megadetector_v2.pb\" --videos \"d:\\temp\\demo_images\\test\"\n",
        "    # python run_tf_detector.py \"d:\\temp\\models\\megadetector_v3.pb\" --videos \"d:\\temp\\test\\in\" --outputDir \"d:\\temp\\test\\out\"\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"detector_file\", type=str)\n",
        "    parser.add_argument(\n",
        "        \"--videos\",\n",
        "        action=\"store\",\n",
        "        type=str,\n",
        "        default=\"\",\n",
        "        help=\"Directory to search for videos, with optional recursion\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--video\",\n",
        "        action=\"store\",\n",
        "        type=str,\n",
        "        default=\"\",\n",
        "        help=\"Single file to process, mutually exclusive with videos\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--threshold\",\n",
        "        action=\"store\",\n",
        "        type=float,\n",
        "        default=DEFAULT_CONFIDENCE_THRESHOLD,\n",
        "        help=\"Confidence threshold, don't render boxes below this confidence\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--recursive\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Recurse into directories, only meaningful if using --videos\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cpu\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Force CPU detection, even if a GPU is available\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Directory for output videos (defaults to same as input)\",\n",
        "    )\n",
        "\n",
        "    if len(sys.argv[1:]) == 0:\n",
        "        parser.print_help()\n",
        "        parser.exit()\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if len(args.video) > 0 and len(args.videos) > 0:\n",
        "        raise Exception(\"Cannot specify both video file and videos dir\")\n",
        "    elif len(args.video) == 0 and len(args.videos) == 0:\n",
        "        raise Exception(\"Must specify either an video file or an videos directory\")\n",
        "\n",
        "    if len(args.video) > 0:\n",
        "        video_file_names = [args.video]\n",
        "    else:\n",
        "        video_file_names = find_videos(args.videos, args.recursive)\n",
        "\n",
        "    if args.forceCpu:\n",
        "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "    # Hack to avoid running on already-detected images\n",
        "    video_file_names = [\n",
        "        x for x in video_file_names if DETECTION_FILENAME_INSERT not in x\n",
        "    ]\n",
        "\n",
        "    print(\"Running detector on {} images\".format(len(video_file_names)))\n",
        "\n",
        "    load_and_run_detector(\n",
        "        model_file=args.detectorFile,\n",
        "        video_file_names=video_file_names,\n",
        "        confidence_threshold=args.threshold,\n",
        "        output_dir=args.outputDir,\n",
        "    )\n",
        "\n",
        "\n",
        "detection_graph = None\n",
        "# Load and run detector on target images\n",
        "print(\"Loading model...\")\n",
        "start_time = time.time()\n",
        "if detection_graph is None:\n",
        "    detection_graph = load_model(\"megadetector_v3.pb\")\n",
        "elapsed = time.time() - start_time\n",
        "print(\"Loaded model in {}\".format(humanfriendly.format_timespan(elapsed)))\n",
        "\n",
        "\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "        n_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "        f = 0\n",
        "        start_time = time.time()\n",
        "        while cap.isOpened():\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if frame is not None:\n",
        "                print(\n",
        "                    \"[INFO] :: Detecting frame {0} out of {1}. Progress {2}%\".format(\n",
        "                        f, n_frames, round(f / n_frames * 100)\n",
        "                    )\n",
        "                )\n",
        "                if ENABLE_ENCHANCER:\n",
        "                    try:\n",
        "                        frame = enchance_image(frame)\n",
        "                    except Exception as e:\n",
        "                        print(\"[ERROR] :: \" + e)\n",
        "\n",
        "                rows = frame.shape[0]\n",
        "                cols = frame.shape[1]\n",
        "                inp = cv.resize(frame, (300, 300))\n",
        "                inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n",
        "\n",
        "                # Run the model\n",
        "                out = sess.run(\n",
        "                    [\n",
        "                        sess.graph.get_tensor_by_name(\"num_detections:0\"),\n",
        "                        sess.graph.get_tensor_by_name(\"detection_scores:0\"),\n",
        "                        sess.graph.get_tensor_by_name(\"detection_boxes:0\"),\n",
        "                        sess.graph.get_tensor_by_name(\"detection_classes:0\"),\n",
        "                    ],\n",
        "                    feed_dict={\n",
        "                        \"image_tensor:0\": inp.reshape(1, inp.shape[0], inp.shape[1], 3)\n",
        "                    },\n",
        "                )\n",
        "\n",
        "                # Visualize detected bounding boxes.\n",
        "\n",
        "                num_detections = int(out[0][0])\n",
        "\n",
        "                detections[\"scores\"].append(out[1][0])\n",
        "                detections[\"classes\"].append(out[3][0])\n",
        "                detections[\"boxes\"].append(out[2][0])\n",
        "                detections[\"numbers\"].append(num_detections)\n",
        "                detections[\"frames\"].append(frame)\n",
        "\n",
        "                # for i in range(num_detections):\n",
        "                #     class_id = int(out[3][0][i])\n",
        "                #     score = float(out[1][0][i])\n",
        "                #     bbox = [float(v) for v in out[2][0][i]]\n",
        "\n",
        "                #     frame = postprocess(frame, class_id, score, bbox)\n",
        "            else:\n",
        "                print(\"[DEBUG] :: Skipping empty frame {}\".format(f))\n",
        "\n",
        "            if ret == True:\n",
        "                f += 1\n",
        "            else:\n",
        "                print(\"[INFO] :: File {0} ended\".format(FILE_INPUT))\n",
        "                elapsed = time.time() - start_time\n",
        "                print(\n",
        "                    \"[INFO] :: Detection took {}\".format(\n",
        "                        humanfriendly.format_timespan(elapsed)\n",
        "                    )\n",
        "                )\n",
        "                avg_score, avg_detect = calculate_stats(n_frames, detections)\n",
        "                if avg_detect > 1:\n",
        "                    postprocess_all(detections, n_frames)\n",
        "                else:\n",
        "                    print(\"[WARN] :: Nothing meaningful found on video\")\n",
        "                # write_raw_video(frames)\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        out_video.release()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "I5vI6sWaxqpg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}